@startuml
skinparam componentStyle rectangle
skinparam wrapWidth 200
skinparam maxMessageSize 200
title AI Tutor – System Architecture

actor User

package "Entry Points" {
  component "Streamlit UI\n(apps/ui.py)" as UI
  component "CLI (`ai-tutor`)" as CLI
  component "Python API" as PythonAPI
}

node "TutorSystem" as TutorSystem {
  component "Settings Loader\n& Logging" as Settings
  component "IngestionPipeline" as Ingestion
  component "Orchestrator Agent\n(tutor_orchestrator)" as Orchestrator
  component "QA Agent\n(qa_agent)" as QA
  component "Web Agent\n(web_agent)" as Web
  component "Visualization Agent\n(viz_agent)" as VizAgent
  component "Ingestion Agent\n(ingestion_agent)" as IngestionAgent
  component "Retriever" as Retriever
  component "EmbeddingClient" as EmbeddingClient
  component "SearchTool" as SearchTool
  component "VectorStore\n(with source filtering)" as VectorStore
  component "ChunkJsonlStore" as ChunkStore
  component "QuizService" as QuizService
  component "ProgressTracker" as ProgressTracker
  component "PersonalizationManager" as Personalizer
  component "Parsers" as Parsers
  component "Chunker" as Chunker
}

database "Vector Store\n(data/vector_store)" as VectorFS
database "Chunks Index\n(data/processed/chunks.jsonl)" as ChunkFS
database "Learner Profiles\n(data/processed/profiles/*.json)" as ProfileFS
database "Session History\n(data/processed/sessions.sqlite)" as SessionFS
folder "Raw Documents\n(data/raw)" as RawDocs
folder "CSV Uploads\n(data/uploads)" as CSVUploads
cloud "OpenAI API\n(gpt-4o-mini)" as OpenAI
cloud "Embedding Provider\n(sentence-transformers)" as EmbeddingProvider

User --> UI : Chat interface
User --> CLI
User --> PythonAPI

UI --> Orchestrator : Natural language\n"create 20 quizzes"\n"plot revenue by month"
UI --> Ingestion : Upload PDFs
UI --> VizAgent : Upload CSV
CLI --> Ingestion : `ingest` command
CLI --> Orchestrator : `ask` command
PythonAPI --> TutorSystem : all operations

Ingestion --> Parsers : parse PDFs/Markdown
Parsers --> RawDocs : read documents
Ingestion --> Chunker : create chunks
Chunker --> EmbeddingClient : embed chunks
EmbeddingClient --> EmbeddingProvider : generate vectors
Ingestion --> VectorStore : store embeddings
VectorStore --> VectorFS : persist .npy + metadata
Ingestion --> ChunkStore : save chunks
ChunkStore --> ChunkFS : persist .jsonl

Orchestrator --> QA : STEM questions
Orchestrator --> Web : current events/non-STEM
Orchestrator --> IngestionAgent : file uploads
Orchestrator --> QuizService : generate_quiz tool
Orchestrator --> VizAgent : visualization requests
Orchestrator --> SessionFS : maintain context

QA --> Retriever : retrieve_local_context
Retriever --> EmbeddingClient : embed query
Retriever --> VectorStore : cosine search\n+ source filter
Web --> SearchTool : web_search

QuizService --> Retriever : find relevant content\n(with source filtering)
QuizService --> OpenAI : generate questions\n(dynamic max_tokens)
QuizService --> ProgressTracker : update profiles
ProgressTracker --> ProfileFS : save learner data
ProgressTracker --> Personalizer : track mastery

VizAgent --> CSVUploads : read CSV files
VizAgent --> OpenAI : generate plot code
VizAgent --> VizAgent : execute code safely

Orchestrator --> OpenAI : stream responses
QA --> OpenAI : generate cited answers
Web --> OpenAI : synthesize web results

note right of Orchestrator
  Agent-First Architecture:
  • Routes via natural language understanding
  • Extracts parameters from user messages
  • Calls specialized tools/agents
  • NEVER answers quiz/viz requests with text
  • Supports "create 20 quizzes from documents"
  • Supports "plot revenue by month"
  
  Daily session rotation prevents token overflow
end note

note right of QuizService
  Quiz Generation:
  • 3-40 questions per quiz
  • Dynamic max_tokens calculation:
    tokens = (num_questions × 150) + 500
  • Source filtering for uploaded docs
  • Topic inference from context
  • Called as agent function tool
  
  Profile Updates by Score:
  • ≥70%: +strength, advance difficulty
  • 40-69%: moderate adjustment
  • <40%: +struggle, easier difficulty
end note

note right of VizAgent
  Visualization Agent:
  • Inspects CSV dataset structure
  • LLM generates matplotlib/seaborn code
  • Safe execution (restricted environment)
  • Returns base64-encoded PNG
  • Supports: line, bar, scatter, histogram,
    pie, heatmap, box plots, etc.
  
  Performance: ~3-5 seconds per plot
end note

note left of VectorStore
  Source Filtering:
  • Can search ONLY specific files
  • 320x faster for uploaded docs
  • Pre-filters by filename before similarity
  • Guarantees relevance to user uploads
  
  Semantic search with cosine similarity
  Optional source_filter parameter
end note

note bottom of UI
  Two Tabs:
  1. Chat & Learn
     - Document upload (PDF/TXT/MD)
     - CSV upload for visualization
     - Interactive Q&A
     - Quiz generation & taking
     - Data visualization
  
  2. Corpus Management
     - Bulk ingestion
     - Corpus statistics
     - Search testing
end note

@enduml
