@startuml
skinparam componentStyle rectangle
skinparam wrapWidth 240
title Agent-First Orchestration

package "Specialist Agents (gpt-4o-mini)" {
  component "QA Agent\nretrieve_local_context" as QAAgent #lightgreen
  component "Web Agent\nweb_search" as WebAgent #lightblue
  component "Visualization Agent\ncreate_visualization" as VizAgent #lightpink
  component "Ingestion Agent\ningest_corpus" as IngestionAgent #lightyellow
}

component "Orchestrator Agent\n(Function Tool Calling)" as Orchestrator #orange
component "generate_quiz\nFunction Tool" as QuizTool #pink
component "QuizService\n(Core Logic)" as QuizService #pink

actor User
User --> Orchestrator : "create 20 quizzes\nfrom documents"\n"plot revenue by month"

Orchestrator --> QAAgent : STEM questions\n(math, physics, CS, etc.)
Orchestrator --> WebAgent : Current events\nhistory, arts
Orchestrator --> IngestionAgent : File uploads
Orchestrator --> QuizTool : Quiz requests\n(extract count & topic)
Orchestrator --> VizAgent : Visualization requests\n(CSV analysis)
QuizTool --> QuizService : Call service logic

QAAgent --> User : Answer with\nlocal citations [1][2]
WebAgent --> User : Answer with\nURL citations
IngestionAgent --> User : Ingestion summary
QuizService --> User : Interactive quiz\n(3-40 questions)
VizAgent --> User : Base64 plot\n+ generated code

note right of Orchestrator
  Agent-First Quiz Generation:
  
  Routing Rules:
  • Math/Science/Tech → qa_agent
  • News/Current → web_agent
  • Upload → ingestion_agent
  • "create N quizzes" → generate_quiz tool
  • "plot/chart/graph" → viz_agent
  
  Count Extraction:
  "create 20 quizzes" → count=20
  "quiz me" → count=4 (default)
  "10 questions on topic" → count=10
  
  Topic Extraction:
  From: user message, uploaded docs, context
  
  FORBIDDEN: Answering quiz requests with text
  REQUIRED: ALWAYS call appropriate tool/agent
end note

note right of VizAgent
  Visualization Agent:
  
  Input:
  • CSV filename
  • User request ("plot X by Y")
  
  Process:
  1. Inspect dataset structure
  2. Generate matplotlib/seaborn code
  3. Execute in safe environment
  4. Return base64-encoded PNG
  
  Supports:
  Line, bar, scatter, histogram,
  pie, heatmap, box plots, etc.
  
  Performance: ~3-5 seconds
end note

note left of QuizTool
  Function Tool:
  
  Parameters:
  • topic: str (broad, searchable)
  • count: int (3-40, enforced)
  • source_filter: Optional[List[str]]
  
  Features:
  ✅ Uses user's exact count
  ✅ Dynamic max_tokens
  ✅ Source filtering for uploads
  ✅ Topic inference from context
  
  Called by orchestrator agent
end note

@enduml

@startuml
skinparam componentStyle rectangle
skinparam wrapWidth 240
title Quiz Generation with Source Filtering

actor Learner
component "Orchestrator Agent" as Orchestrator
component "generate_quiz Tool" as QuizTool
component "QuizService" as QuizService
component "Retriever" as Retriever
component "VectorStore" as VectorStore
component "OpenAI API\n(gpt-4o-mini)" as OpenAI
component "ProgressTracker" as ProgressTracker
database "LearnerProfile\n*.json" as Profile
folder "Uploaded Files" as UploadedFiles

Learner -> Orchestrator : "create 20 quizzes\nfrom uploaded document"
Orchestrator -> Orchestrator : Extract:\n• count=20\n• source_filter=["doc.pdf"]
Orchestrator -> QuizTool : Call tool with params
QuizTool -> QuizService : generate_quiz(topic, count, source_filter)

QuizService -> QuizService : Calculate max_tokens:\n(20 × 150) + 500 = 3500
QuizService -> Retriever : Find content\n+ source_filter
Retriever -> VectorStore : Search ONLY uploaded files\n(320x faster!)
VectorStore -> UploadedFiles : Filter by filename
VectorStore --> Retriever : Top chunks from uploads
Retriever --> QuizService : Relevant passages

QuizService -> OpenAI : Generate 20 questions\nmax_tokens=3500
OpenAI --> QuizService : Quiz with 20×4 choices
QuizService --> Orchestrator : Return quiz object
Orchestrator --> Learner : Display interactive quiz

Learner -> Orchestrator : Submit answers [0,2,1,3...]
Orchestrator -> QuizService : evaluate_quiz(quiz, answers)
QuizService -> QuizService : Grade answers
QuizService -> ProgressTracker : Update profile (score, topic)

ProgressTracker -> Profile : Load profile
ProgressTracker -> ProgressTracker : Calculate deltas based on score
ProgressTracker -> Profile : Save updated profile

QuizService --> Learner : Results + feedback\n+ explanations

note right of QuizService
  Dynamic Token Calculation:
  
  max_tokens = (num_questions × 150) + 500
  
  Examples:
  • 4 questions → 1,100 tokens
  • 20 questions → 3,500 tokens
  • 40 questions → 6,500 tokens
  
  Prevents JSON truncation!
end note

note left of VectorStore
  Source Filtering:
  
  Without filter:
  • Searches all 10,000 chunks
  • Old docs rank higher
  • Slower, less relevant
  
  With filter ["lecture9.pdf"]:
  • Searches only 31 chunks
  • 320x faster!
  • 100% relevance
  • Guaranteed from user's file
end note

note bottom of ProgressTracker
  Profile Updates Based on Score:
  
  ≥70% (Strong):
    +0.12 domain strength
    -0.08 domain struggle
    difficulty = "independent challenge"
  
  40-69% (Moderate):
    +0.06 domain strength
    no struggle change
    difficulty = "guided practice"
  
  <40% (Struggling):
    +0.02 domain strength
    +0.10 domain struggle
    difficulty = "foundational guidance"
  
  Also updates:
  • concepts_mastered[domain] += correct_count
  • total_time_minutes += (questions × 1.5)
  • next_topics based on weak areas
end note

@enduml

@startuml
skinparam componentStyle rectangle
skinparam wrapWidth 220
title Document Upload & Auto-Ingestion

actor User
component "Streamlit UI\n(Chat & Learn tab)" as UI
component "IngestionAgent" as IngestionAgent
component "IngestionPipeline" as Ingestion
component "Parsers\n(PDF, Markdown, TXT)" as Parsers
component "Chunker" as Chunker
component "EmbeddingClient\n(sentence-transformers)" as EmbeddingClient
component "VectorStore\n(with source tracking)" as VectorStore
component "ChunkJsonlStore" as ChunkStore
database "embeddings.npy" as EmbeddingsFile
database "metadata.json\n(includes source paths)" as MetadataFile
database "chunks.jsonl" as ChunksFile

User --> UI : Upload PDF in chat
UI -> UI : Store filename for filtering
User --> UI : Send first message
UI --> IngestionAgent : Auto-trigger ingestion
IngestionAgent --> Ingestion : ingest_file(pdf_path)
Ingestion --> Parsers : Parse PDF
Parsers --> Chunker : Extract text by page
Chunker --> Chunker : Create 500-token chunks\n80-token overlap
Chunker --> EmbeddingClient : Batch encode
EmbeddingClient --> VectorStore : Store vectors\n+ source metadata
VectorStore --> EmbeddingsFile : Append to numpy array
VectorStore --> MetadataFile : Save chunk IDs + sources
Ingestion --> ChunkStore : Save full chunks
ChunkStore --> ChunksFile : Append JSONL

IngestionAgent --> UI : Summary: N chunks indexed
UI --> User : "Ready! Try:\n'create 20 quizzes from this'"

note right of VectorStore
  Source Tracking:
  
  Each chunk metadata includes:
  • source_path: "data/uploads/lecture9.pdf"
  • filename: "lecture9.pdf"
  
  Enables source filtering:
  • Query with source_filter=["lecture9.pdf"]
  • Only searches matching chunks
  • 320x faster, 100% relevant
end note

note left of Chunker
  Smart chunking:
  • Preserves paragraphs
  • Maintains context with overlap
  • Tracks document metadata
  • Page numbers for citations
  • Source path for filtering
end note

note bottom of UI
  Simplified Workflow:
  
  1. Upload PDF in chat
  2. Say "create 20 quizzes from this"
  3. Take quiz immediately!
  
  Features:
  • Auto-ingestion on first message
  • Source filtering enabled
  • Interactive quiz interface
  • Markdown export available
end note

@enduml

@startuml
skinparam componentStyle rectangle
skinparam wrapWidth 240
title Data Visualization Workflow

actor User
component "Streamlit UI\n(Chat & Learn)" as UI
component "Orchestrator Agent" as Orchestrator
component "Visualization Agent" as VizAgent
component "OpenAI API\n(gpt-4o-mini)" as OpenAI
database "CSV Upload\n(data/uploads/*.csv)" as CSVFile

User --> UI : Upload CSV file
UI --> CSVFile : Save to disk
UI --> User : Show preview\n(columns, shape, first 5 rows)

User --> UI : "plot revenue by month"
UI --> Orchestrator : Natural language request
Orchestrator --> Orchestrator : Detect visualization\nkeywords (plot, chart, graph)
Orchestrator --> VizAgent : create_visualization(\ncsv_filename, user_request)

VizAgent --> CSVFile : Read CSV
VizAgent --> VizAgent : Inspect dataset:\n• columns & types\n• sample rows\n• summary stats

VizAgent --> OpenAI : Generate matplotlib code\nwith dataset context
OpenAI --> VizAgent : Python plotting code

VizAgent --> VizAgent : Execute code safely\n(restricted environment)
VizAgent --> VizAgent : Capture plot as\nbase64-encoded PNG

VizAgent --> Orchestrator : Return:\n• image_base64\n• code\n• success/error
Orchestrator --> UI : Display plot + code
UI --> User : Show visualization\n+ code expander

note right of VizAgent
  Dataset Inspection:
  
  Analyzes CSV to extract:
  • Column names & types
  • Numeric vs categorical
  • Sample rows (first 5)
  • Basic statistics (mean, min, max)
  • Value counts for categories
  
  Provides context to LLM for
  intelligent code generation
end note

note left of VizAgent
  Safe Execution:
  
  Restricted environment:
  • Limited imports (pandas, matplotlib, seaborn)
  • No file system access (except reading CSV)
  • No network access
  • No dangerous builtins (exec, eval, etc.)
  • Only safe operations allowed
  
  Returns:
  • Base64-encoded PNG (for display)
  • Generated Python code (for viewing)
  • Error message (if failed)
end note

note bottom of UI
  Supported Visualizations:
  
  • Line charts
  • Bar charts (single/grouped)
  • Scatter plots
  • Histograms
  • Pie charts
  • Heatmaps
  • Box plots
  
  Performance: ~3-5 seconds per plot
  
  Features:
  • Natural language requests
  • Code viewer (expandable)
  • Plot persistence in chat history
  • Multiple plots per session
end note

@enduml
