from __future__ import annotations

import asyncio
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime
import json
from pathlib import Path
from typing import Callable, Dict, List, Optional

from openai.types.responses import ResponseContentPartDoneEvent, ResponseTextDeltaEvent

from agents import Agent, RawResponsesStreamEvent, Runner, function_tool
from agents import SQLiteSession

from .ingestion import build_ingestion_agent
from .qa import build_qa_agent
from .web import build_web_agent

from ai_tutor.config.schema import RetrievalConfig
from ai_tutor.data_models import RetrievalHit
from ai_tutor.ingestion.embeddings import EmbeddingClient
from ai_tutor.learning.models import LearnerProfile
from ai_tutor.learning.quiz import Quiz, QuizService
from ai_tutor.learning.quiz import Quiz, QuizEvaluation, QuizService
from ai_tutor.retrieval.retriever import Retriever
from ai_tutor.retrieval.vector_store import VectorStore
from ai_tutor.search.tool import SearchTool

logger = logging.getLogger(__name__)


@dataclass
class TutorResponse:
    """
    Structured response container for tutor interactions.
    
    This dataclass encapsulates all information returned from a tutoring session,
    including the generated answer, retrieval evidence, personalization hints,
    and optional quiz payloads.
    
    Attributes
    ----------
    answer : str
        The generated response text from the tutor agent. May include citation
        markers like [1], [2] that correspond to the citations list.
    hits : List[RetrievalHit]
        Raw retrieval results from the vector store, containing chunks and similarity
        scores. Empty for web-sourced or quiz-only responses.
    citations : List[str]
        Formatted citation strings (e.g., "[1] Title (Doc: id, Page: 42)") that
        map to bracketed indices in the answer text. Empty if no local sources used.
    style : str
        The explanation style used for this response. One of "scaffolded" (detailed,
        step-by-step), "stepwise" (moderate guidance), or "concise" (advanced).
    next_topic : Optional[str]
        Suggested next topic for the learner based on their current progress and
        knowledge gaps. None if not applicable.
    difficulty : Optional[str]
        Current difficulty level label for the learner in this domain. One of
        "foundational guidance", "guided practice", or "independent challenge".
    source : Optional[str]
        Origin of the answer. One of "local" (RAG from course materials), "web"
        (internet search), "quiz" (assessment generation), or None.
    quiz : Optional[Quiz]
        Generated quiz object if the interaction produced an assessment. Contains
        questions, correct answers, and explanations.
    """

    answer: str
    hits: List[RetrievalHit]
    citations: List[str]
    style: str
    next_topic: Optional[str] = None
    difficulty: Optional[str] = None
    source: Optional[str] = None
    quiz: Optional[Quiz] = None


@dataclass
class AgentState:
    """
    Shared state object for multi-agent communication.
    
    This mutable state container allows specialist agents (QA, Web, Quiz) to
    store their results, which the orchestrator then collects and formats into
    a unified TutorResponse. The state is reset at the start of each new query.
    
    Attributes
    ----------
    last_hits : List[RetrievalHit]
        Retrieval results from the most recent vector search. Used by QA agent
        to pass evidence back to orchestrator.
    last_citations : List[str]
        Formatted citation strings generated by specialist agents. Collected
        and attached to the final response.
    last_source : Optional[str]
        Identifier for the agent that handled the last query ("local", "web", etc.).
        Helps orchestrator determine response formatting.
    last_quiz : Optional[Quiz]
        Quiz object generated by the quiz tool. If present, the response includes
        interactive assessment UI.
    """
    
    last_hits: List[RetrievalHit] = field(default_factory=list)
    last_citations: List[str] = field(default_factory=list)
    last_source: Optional[str] = None
    last_quiz: Optional[Quiz] = None

    def reset(self) -> None:
        """
        Clear all state variables to prepare for a new query.
        
        Called at the start of each answer() invocation to ensure agents don't
        carry over results from previous interactions.
        """
        self.last_hits.clear()
        self.last_citations.clear()
        self.last_source = None
        self.last_quiz = None


class TutorAgent:
    """
    Multi-agent tutoring orchestrator using the OpenAI Agents SDK.
    
    This class implements a hierarchical agent architecture where an orchestrator
    routes student queries to specialist agents based on query type and content.
    The system supports:
    - STEM Q&A with retrieval-augmented generation (QA Agent)
    - Current events and web searches (Web Agent)
    - Document ingestion and corpus management (Ingestion Agent)
    - Interactive quiz generation and evaluation (Quiz Service)
    
    The orchestrator maintains conversation context through SQLite sessions that
    automatically rotate daily to prevent token overflow. All specialist results
    are collected via a shared AgentState object and formatted into structured
    TutorResponse objects.
    
    Architecture
    ------------
    Student Query → Orchestrator Agent → [QA | Web | Ingestion] Agent → Response
                                       ↘ Quiz Service → Interactive Assessment
    
    Attributes
    ----------
    MIN_CONFIDENCE : float
        Minimum similarity score (0.2) for retrieval results to be considered
        relevant. Queries with no hits above this threshold fall back to web search.
    retriever : Retriever
        Vector search coordinator that embeds queries and retrieves similar chunks.
    search_tool : SearchTool
        Web search interface (DuckDuckGo) used by the Web Agent.
    ingest_fn : Callable
        Directory ingestion function for processing and indexing new documents.
    sessions : Dict[str, SQLiteSession]
        In-memory cache of active conversation sessions, keyed by learner_id.
    state : AgentState
        Shared mutable state for inter-agent communication.
    session_db_path : Path
        SQLite database path for persistent conversation history.
    quiz_service : QuizService
        Assessment generator that creates and evaluates quizzes.
    """

    MIN_CONFIDENCE = 0.2  # Minimum retrieval score for accepting local results

    def __init__(
        self,
        retrieval_config: RetrievalConfig,
        embedder: EmbeddingClient,
        vector_store: VectorStore,
        search_tool: SearchTool,
        ingest_directory: Callable[[Path], object],
        session_db_path: Path,
        quiz_service: QuizService,
    ):
        """
        Initialize the multi-agent system with all required dependencies.
        
        Parameters
        ----------
        retrieval_config : RetrievalConfig
            Configuration for vector search (top_k, thresholds, etc.).
        embedder : EmbeddingClient
            Sentence transformer for encoding queries and documents.
        vector_store : VectorStore
            Indexed vector database for similarity search.
        search_tool : SearchTool
            Web search interface for non-local queries.
        ingest_directory : Callable[[Path], object]
            Function to process and index documents from a directory.
        session_db_path : Path
            SQLite database path for conversation persistence.
        quiz_service : QuizService
            Service for generating and evaluating assessments.
        """
        # Core retrieval infrastructure
        self.retriever = Retriever(retrieval_config, embedder=embedder, vector_store=vector_store)
        self.search_tool = search_tool
        self.ingest_fn = ingest_directory
        
        # Session and state management
        self.sessions: Dict[str, SQLiteSession] = {}  # Learner ID → Active session
        self.state = AgentState()  # Shared state for agent communication
        self.session_db_path = session_db_path
        
        # Quiz and assessment infrastructure
        self.quiz_service = quiz_service
        
        # Temporary context for quiz generation (set during answer() calls)
        self._active_profile: Optional[LearnerProfile] = None
        self._active_extra_context: Optional[str] = None

        # Agent instances (initialized in _build_agents)
        self.ingestion_agent: Agent | None = None
        self.qa_agent: Agent | None = None
        self.web_agent: Agent | None = None
        self.orchestrator_agent: Agent | None = None

        self._build_agents()

    def _build_agents(self) -> None:
        """
        Construct the multi-agent hierarchy with proper handoff configuration.
        
        This method builds three specialist agents and one orchestrator:
        1. Ingestion Agent: Handles document upload and processing requests
        2. Web Agent: Performs web searches for non-local knowledge
        3. QA Agent: Answers STEM questions using RAG over course materials
        4. Orchestrator: Routes queries to appropriate specialists
        
        The QA Agent is configured with a handoff to the Web Agent, allowing
        automatic fallback when local retrieval yields insufficient results.
        
        Additionally, a generate_quiz tool is defined inline to enable the
        orchestrator to create assessments without agent handoff overhead.
        """
        # Build specialist agents
        self.ingestion_agent = build_ingestion_agent(self.ingest_fn)
        self.web_agent = build_web_agent(self.search_tool, self.state)
        self.qa_agent = build_qa_agent(
            self.retriever, 
            self.state, 
            self.MIN_CONFIDENCE, 
            handoffs=[self.web_agent]  # Allow QA → Web fallback
        )

        @function_tool
        def generate_quiz(topic: str, count: int = 4, difficulty: str | None = None) -> str:
            """
            Function tool for quiz generation, callable by the orchestrator agent.
            
            This tool validates parameters, generates a quiz using the quiz service,
            and stores the result in shared state for collection by the orchestrator.
            
            Parameters
            ----------
            topic : str
                Subject matter for the quiz (e.g., "derivatives", "Newton's laws").
            count : int, default=4
                Number of questions to generate. Clamped to range [3, 8].
            difficulty : str | None, optional
                Explicit difficulty level. If None, inferred from learner profile.
            
            Returns
            -------
            str
                Confirmation message for the orchestrator to relay to the student.
            """
            # Validate and clamp question count to reasonable range
            try:
                question_count = int(count)
            except (TypeError, ValueError):
                question_count = 4
            question_count = max(3, min(question_count, 8))  # Enforce [3-8] range
            
            # Access the currently active learner profile (set by answer() method)
            profile = self._active_profile
            
            # Generate quiz using the quiz service with all available context
            quiz = self.quiz_service.generate_quiz(
                topic=topic,
                profile=profile,
                num_questions=question_count,
                difficulty=difficulty,
                extra_context=self._active_extra_context,  # Include uploaded docs
            )
            
            # Store in shared state for orchestrator collection
            self.state.last_quiz = quiz
            self.state.last_source = "quiz"
            
            # Return message for orchestrator to communicate quiz readiness
            return (
                f"Prepared a {len(quiz.questions)}-question quiz on {quiz.topic}. "
                "Let the learner know the quiz is ready for them to take."
            )

        handoffs = [agent for agent in (self.ingestion_agent, self.qa_agent, self.web_agent) if agent is not None]
        self.orchestrator_agent = Agent(
            name="tutor_orchestrator",
            model="gpt-4o-mini",
            instructions=(
                "You are the orchestrator agent in a multi-agent tutoring system. Your job is to decide whether to answer a query yourself or delegate it to a specialist agent.\n\n"
                "ROUTING RULES:\n\n"

                "STEM Questions → qa_agent\n"
                "If the question is about:\n"
                "- Math (equations, formulas, calculations, proofs)\n"
                "- Physics (laws, forces, energy, motion, thermodynamics, etc.)\n"
                "- Chemistry (reactions, molecules, elements, bonds)\n"
                "- Biology (cells, genetics, organisms, photosynthesis)\n"
                "- Engineering (circuits, structures, systems)\n"
                "- Computer Science (algorithms, data structures, programming)\n"
                "- Any technical or scientific concept, definition, or explanation\n"
                "→ IMMEDIATELY hand off to qa_agent\n\n"

                "Current Events / Non-STEM → web_agent\n"
                "- Recent news, current events, politics\n"
                "- History, literature, arts\n"
                "- Anything requiring up-to-date information\n"
                "→ Hand off to web_agent\n\n"

                "File Upload → ingestion_agent\n"
                "- User wants to upload, ingest, or add documents\n"
                "→ Hand off to ingestion_agent\n\n"

                "Quiz Request → Use generate_quiz tool\n"
                "- User asks for quiz, test, practice questions\n"
                "→ Call generate_quiz(topic, count)\n\n"

                "ONLY Answer Directly:\n"
                "- 'What can you help with?' or system capability questions\n"
                "- 'What's my progress?' or profile questions\n"
                "- 'Hello' or greetings\n\n"

                "CRITICAL RULES:\n"
                "- DO NOT try to answer STEM questions yourself\n"
                "- DO NOT explain concepts directly\n"
                "- Your job is ROUTING, not answering\n"
                "- If unsure, hand off to qa_agent\n"
                "- Example: 'What is the Bernoulli equation?' → Hand off to qa_agent immediately"
            ),
            tools=[generate_quiz],
            handoffs=handoffs,
        )

    def create_quiz(
        self,
        *,
        topic: str,
        profile: Optional[LearnerProfile],
        num_questions: int = 4,
        difficulty: Optional[str] = None,
        extra_context: Optional[str] = None,
    ) -> Quiz:
        """Generate a multiple-choice quiz tailored to the learner."""
        return self.quiz_service.generate_quiz(
            topic=topic,
            profile=profile,
            num_questions=num_questions,
            difficulty=difficulty,
            extra_context=extra_context,
        )

    def evaluate_quiz(
        self,
        *,
        quiz: Quiz,
        answers: List[int],
        profile: Optional[LearnerProfile],
    ) -> QuizEvaluation:
        """Score a learner's quiz submission and return detailed feedback."""
        return self.quiz_service.evaluate_quiz(
            quiz=quiz,
            answers=answers,
            profile=profile,
        )

    def answer(
        self,
        learner_id: str,
        question: str,
        mode: str,
        style_hint: str,
        profile: Optional[LearnerProfile] = None,
        extra_context: Optional[str] = None,
        on_delta: Optional[Callable[[str], None]] = None,
    ) -> TutorResponse:
        """Synchronously orchestrate the multi-agent run and produce a TutorResponse."""
        return asyncio.run(
            self._answer_async(
                learner_id=learner_id,
                question=question,
                mode=mode,
                style_hint=style_hint,
                profile=profile,
                extra_context=extra_context,
                on_delta=on_delta,
            )
        )

    async def _answer_async(
        self,
        learner_id: str,
        question: str,
        mode: str,
        style_hint: str,
        profile: Optional[LearnerProfile],
        extra_context: Optional[str],
        on_delta: Optional[Callable[[str], None]],
    ) -> TutorResponse:
        session = self._get_session(learner_id)
        self.state.reset()

        # For orchestrator: minimal prompt with just the question
        # The specialist agents will get the full context with style hints
        if self.orchestrator_agent:
            prompt_sections: List[str] = []
            if profile:
                prompt_sections.append("Learner profile summary:")
                prompt_sections.append(self._render_profile_summary(profile))
                prompt_sections.append("")
            prompt_sections.append("Question:")
            prompt_sections.append(question)
            prompt = "\n".join(prompt_sections)
        else:
            # Fallback for when orchestrator is not used
            system_preamble = (
                f"Learner mode: {mode}. Preferred explanation style: {style_hint}. "
                "Cite supporting evidence using bracketed indices or URLs when available."
            )
            prompt_sections: List[str] = [system_preamble, ""]

            if profile:
                prompt_sections.append("Learner profile summary:")
                prompt_sections.append(self._render_profile_summary(profile))
                prompt_sections.append("")

            if extra_context:
                prompt_sections.append("Session documents:")
                prompt_sections.append(extra_context)
                prompt_sections.append("")

            prompt_sections.append("Question:")
            prompt_sections.append(question)
            prompt = "\n".join(prompt_sections)

        self._active_profile = profile
        self._active_extra_context = extra_context
        self.state.last_quiz = None
        try:
            raw_answer = await self._run_specialist(
                prompt,
                session,
                on_delta,
            )
        finally:
            self._active_profile = None
            self._active_extra_context = None
        quiz_payload: Optional[Quiz] = None
        answer_text = raw_answer
        if raw_answer.strip().startswith("{"):
            processed, computed_quiz = self._process_quiz_directive(
                raw_answer,
                profile=profile,
                extra_context=extra_context,
            )
            if computed_quiz is not None:
                quiz_payload = computed_quiz
                answer_text = processed
        if quiz_payload is None and self.state.last_quiz is not None:
            quiz_payload = self.state.last_quiz
        if quiz_payload is None and self._should_force_quiz(question):
            quiz_payload = self.quiz_service.generate_quiz(
                topic=self._infer_topic_from_request(question),
                profile=profile,
                num_questions=self._infer_count_from_request(question),
                difficulty=None,
                extra_context=extra_context,
            )
            self.state.last_quiz = quiz_payload
            answer_text = (
                f"I've prepared a {len(quiz_payload.questions)}-question quiz on {quiz_payload.topic}. "
                "Scroll down to take it when you're ready."
            )
        if not quiz_payload and not self.state.last_citations:
            answer_text = self._strip_citation_markers(answer_text)
        if quiz_payload is None:
            processed, computed_quiz = self._process_quiz_directive(
                answer_text,
                profile=profile,
                extra_context=extra_context,
            )
            if computed_quiz is not None:
                quiz_payload = computed_quiz
                answer_text = processed
        hits = self.state.last_hits if not quiz_payload else []
        citations = self.state.last_citations if not quiz_payload else []
        source = "quiz" if quiz_payload else self.state.last_source

        return TutorResponse(
            answer=answer_text,
            hits=hits,
            citations=citations,
            style=style_hint,
            source=source,
            quiz=quiz_payload,
        )

    def _get_session(self, learner_id: str) -> SQLiteSession:
        """
        Get or create a conversation session with automatic daily rotation.
        
        This method implements token overflow prevention through date-based session
        keys. Each day, a new session is created, limiting the conversation context
        to same-day interactions. This prevents prompt length from growing unbounded
        while maintaining coherent within-session context.
        
        Session Key Format
        ------------------
        ai_tutor_{learner_id}_{YYYYMMDD}
        
        Example: "ai_tutor_student123_20251023"
        
        Parameters
        ----------
        learner_id : str
            Unique identifier for the learner (used for profile lookup and session key).
        
        Returns
        -------
        SQLiteSession
            Active session object for this learner and date. Contains all conversation
            history from today's interactions.
        
        Notes
        -----
        - Sessions are cached in memory for performance
        - Automatic rotation occurs at midnight (based on server timezone)
        - Previous sessions remain in SQLite but are not loaded into context
        - Manual clearing available via clear_session() or clear_sessions.py script
        """
        # Use date-based session IDs to auto-rotate daily (prevents token accumulation)
        # This limits context to same-day conversations
        today = datetime.now().strftime("%Y%m%d")
        session_key = f"ai_tutor_{learner_id}_{today}"
        
        # Check if we have a cached session for this learner
        session = self.sessions.get(learner_id)
        
        # Create new session if none exists or if session key changed (new day)
        if session is None or getattr(session, '_session_key', None) != session_key:
            session = SQLiteSession(
                session_key,
                db_path=str(self.session_db_path),
            )
            # Store session key for comparison on next access
            session._session_key = session_key  # type: ignore
            self.sessions[learner_id] = session
            logger.debug(f"Created new session for {learner_id}: {session_key}")
        
        return session
    
    def clear_session(self, learner_id: str) -> None:
        """
        Clear the in-memory conversation session for a learner.
        
        This removes the cached session from memory, forcing creation of a fresh
        session on the next interaction. The SQLite database retains historical
        records, but they won't be loaded into the agent's context.
        
        Parameters
        ----------
        learner_id : str
            Unique identifier for the learner whose session should be cleared.
        
        Notes
        -----
        - Only removes from memory cache, not from SQLite database
        - To permanently delete from database, use scripts/clear_sessions.py
        - Next interaction will create a fresh session with no conversation history
        """
        if learner_id in self.sessions:
            del self.sessions[learner_id]
        # Note: This doesn't delete from SQLite, just removes from memory
        # The session will start fresh on next question

    @staticmethod
    def _strip_citation_markers(answer: str) -> str:
        cleaned = re.sub(r"\[\s*\d+(?:\s*,\s*\d+)*\s*\]", "", answer)
        return re.sub(r"\s{2,}", " ", cleaned).strip()

    @staticmethod
    def _render_profile_summary(profile: LearnerProfile) -> str:
        lines = [
            f"Name: {profile.name or profile.learner_id}",
            f"Total study time (minutes): {profile.total_time_minutes:.1f}",
        ]
        if profile.domain_strengths:
            strengths = sorted(profile.domain_strengths.items(), key=lambda item: item[1], reverse=True)[:3]
            strength_lines = ", ".join(f"{domain}: {score:.2f}" for domain, score in strengths)
            lines.append(f"Domain strengths: {strength_lines}")
        if profile.difficulty_preferences:
            prefs = ", ".join(f"{domain}: {pref}" for domain, pref in list(profile.difficulty_preferences.items())[:3])
            lines.append(f"Difficulty preferences: {prefs}")
        if profile.next_topics:
            next_topics = ", ".join(f"{domain}: {topic}" for domain, topic in list(profile.next_topics.items())[:3])
            lines.append(f"Upcoming topics: {next_topics}")
        return "\n".join(lines)

    def _process_quiz_directive(
        self,
        answer_text: str,
        profile: Optional[LearnerProfile],
        extra_context: Optional[str],
    ) -> tuple[str, Optional[Quiz]]:
        text = answer_text.strip()
        if not text.startswith("{"):
            return answer_text, None
        try:
            payload = json.loads(text)
        except json.JSONDecodeError:
            return answer_text, None
        if not isinstance(payload, dict):
            return answer_text, None
        if payload.get("action") != "generate_quiz":
            return answer_text, None

        topic_raw = payload.get("topic") or payload.get("subject") or "general review"
        topic = str(topic_raw).strip() or "general review"
        count_raw = payload.get("count") or payload.get("num_questions") or 4
        try:
            count = int(count_raw)
        except (TypeError, ValueError):
            count = 4
        count = max(3, min(count, 8))
        message = str(payload.get("message") or "").strip()

        quiz = self.quiz_service.generate_quiz(
            topic=topic,
            profile=profile,
            num_questions=count,
            difficulty=None,
            extra_context=extra_context,
        )
        if not message:
            message = f"I've prepared a {count}-question quiz on {quiz.topic}. Scroll down to take it."
        return message, quiz

    @staticmethod
    def _should_force_quiz(question: str) -> bool:
        lowered = question.lower()
        keywords = [
            "quiz",
            "quizzes",
            "practice questions",
            "practice quiz",
            "give me questions",
            "mcq",
            "multiple choice",
            "test me",
        ]
        return any(keyword in lowered for keyword in keywords)

    @staticmethod
    def _infer_topic_from_request(question: str) -> str:
        match = re.search(r"(?:about|on|regarding)\s+(.+)", question, flags=re.IGNORECASE)
        topic = match.group(1).strip() if match else question.strip()
        topic = re.sub(r"[\.\?!]+$", "", topic)
        return topic or "general review"

    @staticmethod
    def _infer_count_from_request(question: str) -> int:
        match = re.search(r"(\d+)\s*(?:question|questions|quiz|quizzes|mcq)", question, flags=re.IGNORECASE)
        if not match:
            match = re.search(r"(\d+)", question)
        if match:
            try:
                value = int(match.group(1))
                return max(3, min(value, 8))
            except ValueError:
                pass
        return 4

    async def _run_specialist(
        self,
        prompt: str,
        session: SQLiteSession,
        on_delta: Optional[Callable[[str], None]],
    ) -> str:
        final_tokens: List[str] = []

        agent_to_run = self.orchestrator_agent or self.qa_agent
        stream = Runner.run_streamed(agent_to_run, input=prompt, session=session)
        async for event in stream.stream_events():
            if not isinstance(event, RawResponsesStreamEvent):
                continue
            data = event.data
            if isinstance(data, ResponseTextDeltaEvent):
                final_tokens.append(data.delta)
                if on_delta:
                    on_delta(data.delta)
            elif isinstance(data, ResponseContentPartDoneEvent) and on_delta:
                on_delta("\n")

        if self.orchestrator_agent is None and not self.state.last_source and self.web_agent is not None:
            if on_delta:
                on_delta("[info] No local evidence, searching the web...\n")
            self.state.reset()
            final_tokens.clear()
            stream = Runner.run_streamed(self.web_agent, input=prompt, session=session)
            async for event in stream.stream_events():
                if not isinstance(event, RawResponsesStreamEvent):
                    continue
                data = event.data
                if isinstance(data, ResponseTextDeltaEvent):
                    final_tokens.append(data.delta)
                    if on_delta:
                        on_delta(data.delta)
                elif isinstance(data, ResponseContentPartDoneEvent) and on_delta:
                    on_delta("\n")

        return "".join(final_tokens).strip()
