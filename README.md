# ğŸ“ AI Tutor

An intelligent tutoring system that ingests STEM course materials, answers questions with cited references, generates personalized quizzes, and creates data visualizationsâ€”all through natural conversation.

## âœ¨ Key Features

- **ğŸ“š Smart Document Upload** â€“ Upload PDFs/TXT in chat, auto-ingest on first question
- **ğŸ¤– Agent-First Architecture** â€“ Intelligent orchestrator routes requests to specialized tools
- **ğŸ“ Natural Language Quizzes** â€“ "Create 20 questions from uploaded documents" (3-40 questions)
- **ğŸ’¬ Interactive Quiz Interface** â€“ Take quizzes in chat with immediate feedback
- **ğŸ“Š Data Visualization** â€“ Upload CSV, request plots: "plot revenue by month"
- **ğŸ” Source-Filtered Retrieval** â€“ Search specific documents only (320x faster)
- **ğŸ¯ Adaptive Learning** â€“ Track progress, adjust difficulty automatically
- **ğŸŒ Web Search** â€“ Falls back to current information when needed

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.10+
pip install -r requirements.txt

# Set your OpenAI API key
export OPENAI_API_KEY=your_key_here
```

### Launch the App

```bash
streamlit run apps/ui.py
```

The app opens at `http://localhost:8501` with two tabs:
- **ğŸ’¬ Chat & Learn** â€“ Q&A, quizzes, visualizations
- **ğŸ“š Corpus Management** â€“ Browse and manage documents

## ğŸ’¬ How to Use

### 1. Ask Questions

```
You: "Explain the Bernoulli equation"
AI: [Provides answer with citations from local documents]
```

### 2. Upload Documents & Generate Quizzes

```
1. In sidebar, upload PDF(s) under "ğŸ“¤ Upload Documents"
2. System auto-ingests when you ask first question
3. Say: "create 20 questions from the uploaded documents"
4. Take the quiz interactively!
5. Click "Edit and Download Quiz" for markdown export
```

### 3. Data Visualization

```
1. In sidebar, upload CSV under "ğŸ“Š Data Visualization"
2. System shows preview (columns, shape, first 5 rows)
3. Say: "plot revenue by month"
4. System generates matplotlib code and displays chart
5. Click "View generated code" to see Python code
```

### Example Requests

```
# Questions
"Explain R-CNN architecture"
"What is recursion?"
"How does photosynthesis work?"

# Quizzes
"create 10 questions on machine learning"
"quiz me on Newton's Laws"
"create 30 questions from uploaded document"

# Visualizations
"create a bar chart of sales by region"
"show me a histogram of temperatures"
"scatter plot of X vs Y"
"line chart comparing revenue and expenses"
```

## ğŸ—ï¸ Architecture

### System Overview

```
User Message â†’ Orchestrator Agent â†’ Specialized Tools/Agents
    â†“
    â”œâ”€â†’ generate_quiz tool â†’ Quiz (3-40 questions)
    â”œâ”€â†’ QA Agent â†’ Retriever â†’ Answer with citations
    â”œâ”€â†’ Visualization Agent â†’ Plot generation
    â”œâ”€â†’ Web Agent â†’ Current information
    â””â”€â†’ Ingestion Agent â†’ Document processing
```

### Core Components

**1. Document Ingestion**
- Supports PDF, TXT, Markdown
- Semantic chunking (512 tokens)
- Vector embeddings (all-MiniLM-L6-v2)
- Metadata tracking (title, page, source)

**2. Retrieval System**
- ChromaDB vector store (default, production-ready)
- Vector similarity search with cosine distance
- Source filtering for uploaded documents
- Top-k configurable (default: 5-8)
- Citation generation with page numbers
- Automatic persistence (SQLite backend)

**3. QA Agent**
- Retrieval-augmented generation
- Context-aware responses
- Multi-document support
- Automatic citation tracking

**4. Quiz Generation**
- Dynamic question count (3-40)
- Topic extraction from context
- Multiple choice format
- Source-filtered retrieval
- Interactive UI + Markdown export

**5. Visualization Agent**
- CSV dataset inspection
- LLM-powered code generation (matplotlib/seaborn)
- Safe execution environment
- Base64 image encoding
- Code display in UI

**6. Adaptive Learning**
- Learner profiling by domain
- Performance tracking
- Difficulty adjustment
- Progress monitoring

## ğŸ“Š Quiz Generation

### Capabilities

- **3-40 questions** per quiz
- **Automatic topic extraction** from uploaded documents
- **Document grounding** â€“ Questions based on YOUR files
- **Interactive interface** â€“ Radio buttons, instant feedback
- **Markdown export** â€“ Download and share

### How It Works

```
User: "create 20 questions from the documents"
  â†“
Orchestrator extracts: topic='computer vision', count=20
  â†“
Calls: generate_quiz(topic='computer vision', count=20)
  â†“
Quiz Service:
  â€¢ Retrieves content from uploaded docs (source filtering)
  â€¢ Calculates max_tokens dynamically: (20 Ã— 150) + 500 = 3500
  â€¢ Generates 20 questions with LLM
  â†“
UI displays interactive quiz
  â†“
User takes quiz, gets results & explanations
```

### Performance

| Metric | Value |
|--------|-------|
| Question count | 3-40 per quiz |
| Generation time | ~8-15 seconds (10 questions) |
| Retrieval time | 50-200ms (with source filtering) |
| Export format | Markdown |

## ğŸ“ˆ Data Visualization

### Supported Charts

- Line charts
- Bar charts (single/grouped)
- Scatter plots
- Histograms
- Pie charts
- Heatmaps
- Box plots

### Workflow

```
1. Upload: sales_2024.csv (12 rows Ã— 3 columns: month, revenue, expenses)
2. Request: "plot revenue by month"
3. Agent:
   â€¢ Inspects dataset (columns, types, sample rows)
   â€¢ Generates matplotlib code via LLM
   â€¢ Executes in safe environment
   â€¢ Returns base64-encoded PNG
4. UI displays plot in chat
5. User clicks "View generated code" to see Python
```

### Performance

| Metric | Time |
|--------|------|
| Dataset inspection | ~50-100ms |
| Code generation (LLM) | ~2-4 seconds |
| Code execution | ~500-1000ms |
| **Total** | **~3-5 seconds** |

## ğŸ” Retrieval Features

### Vector Store

- **Embeddings**: `all-MiniLM-L6-v2` (384 dimensions)
- **Storage**: In-memory numpy arrays + metadata
- **Similarity**: Cosine similarity search
- **Metadata**: Title, page, domain, source path

### Source Filtering

Search ONLY uploaded documents:

```python
Query(
    text="machine learning",
    source_filter=["lecture9.pdf", "lecture10.pdf"]
)
```

**Benefits:**
- **320x faster** (31 chunks vs 10,000)
- **Better ranking** (no old document competition)
- **100% relevant** to user's files

## ğŸ“Š Learner Profiles

### Tracked Metrics

- Strengths/struggles per domain (e.g., "Physics-Mechanics")
- Study time and questions mastered
- Quiz performance over time
- Difficulty progression

### Adaptive Adjustment

| Quiz Score | Action | Next Step |
|------------|--------|-----------|
| â‰¥ 70% | Challenge | Harder topics |
| 40-69% | Guided | Targeted practice |
| < 40% | Foundational | Review basics |

## ğŸ—‚ï¸ Data Storage

```
data/
â”œâ”€â”€ raw/                      # Original documents (PDFs, MD, TXT)
â”œâ”€â”€ uploads/                  # CSV files for visualization
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ chunks.jsonl         # Extracted and chunked content
â”‚   â”œâ”€â”€ profiles/            # Learner profiles (JSON)
â”‚   â””â”€â”€ sessions.sqlite      # Conversation history
â””â”€â”€ vector_store/
    â”œâ”€â”€ embeddings.npy       # Vector embeddings
    â””â”€â”€ metadata.json        # Chunk metadata
```

## âš™ï¸ Configuration

Edit `config/default.yaml`:

```yaml
model:
  name: gpt-4o-mini
  temperature: 0.7
  max_output_tokens: 1024  # Auto-adjusted for large quizzes

retrieval:
  top_k: 8
  embedding_model: all-MiniLM-L6-v2

quiz:
  default_questions: 4
  max_questions: 40
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# With coverage
pytest --cov=src/ai_tutor tests/

# Specific component
pytest tests/test_quiz_generation.py
```

## ğŸ“š Documentation

- **[Demo Guide](docs/demo.md)** â€“ Use cases and workflows
- **[Technical Report](docs/presentation_report.md)** â€“ System architecture
- **[Architecture Diagrams](docs/architecture.puml)** â€“ PlantUML diagrams

## ğŸ”§ Advanced Usage

### CLI Commands

```bash
# Ingest documents
ai-tutor ingest ./data/raw

# Ask a question
ai-tutor ask student123 "What is the Bernoulli equation?"

# Clear conversation history
python scripts/clear_sessions.py student123
```

### Programmatic Usage

```python
from ai_tutor.system import TutorSystem

# Initialize
system = TutorSystem.from_yaml("config/default.yaml")

# Ingest documents
system.ingest_directory("./data/raw")

# Ask a question
response = system.answer_question(
    learner_id="student123",
    question="Explain neural networks",
)

print(response.answer)
print(response.citations)
```

## ğŸ”„ Session Management

Sessions are stored in SQLite with daily rotation:

**Format**: `ai_tutor_{learner_id}_{YYYYMMDD}`

**Auto-rotation**: Prevents token overflow

**Manual clearing**:
```bash
# View all sessions
python scripts/clear_sessions.py

# Clear specific learner
python scripts/clear_sessions.py student123

# Clear all
python scripts/clear_sessions.py all
```

## ğŸ¯ Key Innovations

1. **Agent-First Design** â€“ Natural language over button-based UI
2. **Source Filtering** â€“ Search only relevant documents (320x speedup)
3. **Dynamic Token Allocation** â€“ Auto-scales for 3-40 question quizzes
4. **LLM-Powered Visualization** â€“ Generate plotting code from descriptions
5. **Safe Code Execution** â€“ Restricted environment for plot generation
6. **Citation Transparency** â€“ Every answer traceable to source

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) for details

## ğŸ™ Acknowledgments

- OpenAI API for LLM capabilities
- Sentence-Transformers for embeddings
- Streamlit for UI framework
- matplotlib/seaborn for visualizations

---

**Built with â¤ï¸ for personalized STEM education**

For questions, open a GitHub issue or contact the maintainers.
